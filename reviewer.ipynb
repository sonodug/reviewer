{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonodug/reviewer/blob/main/reviewer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETs-HUq3nfcF"
      },
      "source": [
        "load data file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "dyVwsQnNmcLD",
        "outputId": "f8d524f3-4d2e-4e1e-aefb-afa49b39d443"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1af7287f-1a2e-40f5-8c7a-f61c273191df\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1af7287f-1a2e-40f5-8c7a-f61c273191df\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving pikabu.txt to pikabu.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files  \n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOdxm6YwpDZp"
      },
      "source": [
        "load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3f9AVa_niRl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG3-wYvepGPT"
      },
      "source": [
        "check file lenght"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4HZuYcQn967",
        "outputId": "8bc417cb-33f1-4c92-8b74-6a2fb200186e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 680534 characters\n"
          ]
        }
      ],
      "source": [
        "text = open('pikabu.txt', 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sVJoqjZoJqL",
        "outputId": "fc00ae5f-415e-430d-cd62-abadcc4d3edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Похоже я заболел коронавирусом... Ч.4\n",
            "9 фактов об антибиотиках и резистентности к ним + хорошая новость\n",
            "Как на меня повлиял карантин со всеми вытекающими последствиями\n",
            "После карантина\n",
            "Очередная изоляция\n",
            "В шкуре красавчика. Хотя бы так\n",
            "Перу, опять кар\n"
          ]
        }
      ],
      "source": [
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9TbGtk1pJzb"
      },
      "source": [
        "check amount of unique characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25ra6AILoOxN",
        "outputId": "41e8f12a-ed77-4773-8d82-c3b1afcac6ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175 unique characters\n"
          ]
        }
      ],
      "source": [
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxuMPP3tqxeW"
      },
      "source": [
        "exaple of text processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXwRYknjoYdz",
        "outputId": "021bf472-09cb-4255-96f5-1503c5c14cf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUzRAzKBpU1E"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84sD4Gwapa5r",
        "outputId": "cc50967b-fbe5-4e54-9b62-150b806deb97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[66, 67, 68, 69, 70, 71, 72], [89, 90, 91]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8Har8O0pmgk"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRYhkTwLpvEt",
        "outputId": "e58cd551-de22-4f4c-bbfe-49186e735bd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lfbr8Kmp6XO",
        "outputId": "c9c89549-308c-4800-e518-5f5e6d8784a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al59e5j2qGRL"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXW8PvTJq56s"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqaZioI1qNmU",
        "outputId": "a59ffe63-577a-4410-f1e8-eb534c836fbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(680534,), dtype=int64, numpy=array([115, 146, 153, ...,  83,  85,  16])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz4W8Hn0q9T6"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MEFxGxTrAGE",
        "outputId": "f6bb0b5a-54cf-4546-fcc9-101d45f52c85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "П\n",
            "о\n",
            "х\n",
            "о\n",
            "ж\n",
            "е\n",
            " \n",
            "я\n",
            " \n",
            "з\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la6c4khQrBKy"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEX07II5rQ10",
        "outputId": "79e24663-d13b-4bce-f3bc-d751d63bd636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\\xd0\\x9f' b'\\xd0\\xbe' b'\\xd1\\x85' b'\\xd0\\xbe' b'\\xd0\\xb6' b'\\xd0\\xb5'\n",
            " b' ' b'\\xd1\\x8f' b' ' b'\\xd0\\xb7' b'\\xd0\\xb0' b'\\xd0\\xb1' b'\\xd0\\xbe'\n",
            " b'\\xd0\\xbb' b'\\xd0\\xb5' b'\\xd0\\xbb' b' ' b'\\xd0\\xba' b'\\xd0\\xbe'\n",
            " b'\\xd1\\x80' b'\\xd0\\xbe' b'\\xd0\\xbd' b'\\xd0\\xb0' b'\\xd0\\xb2' b'\\xd0\\xb8'\n",
            " b'\\xd1\\x80' b'\\xd1\\x83' b'\\xd1\\x81' b'\\xd0\\xbe' b'\\xd0\\xbc' b'.' b'.'\n",
            " b'.' b' ' b'\\xd0\\xa7' b'.' b'4' b'\\n' b'9' b' ' b'\\xd1\\x84' b'\\xd0\\xb0'\n",
            " b'\\xd0\\xba' b'\\xd1\\x82' b'\\xd0\\xbe' b'\\xd0\\xb2' b' ' b'\\xd0\\xbe'\n",
            " b'\\xd0\\xb1' b' ' b'\\xd0\\xb0' b'\\xd0\\xbd' b'\\xd1\\x82' b'\\xd0\\xb8'\n",
            " b'\\xd0\\xb1' b'\\xd0\\xb8' b'\\xd0\\xbe' b'\\xd1\\x82' b'\\xd0\\xb8' b'\\xd0\\xba'\n",
            " b'\\xd0\\xb0' b'\\xd1\\x85' b' ' b'\\xd0\\xb8' b' ' b'\\xd1\\x80' b'\\xd0\\xb5'\n",
            " b'\\xd0\\xb7' b'\\xd0\\xb8' b'\\xd1\\x81' b'\\xd1\\x82' b'\\xd0\\xb5' b'\\xd0\\xbd'\n",
            " b'\\xd1\\x82' b'\\xd0\\xbd' b'\\xd0\\xbe' b'\\xd1\\x81' b'\\xd1\\x82' b'\\xd0\\xb8'\n",
            " b' ' b'\\xd0\\xba' b' ' b'\\xd0\\xbd' b'\\xd0\\xb8' b'\\xd0\\xbc' b' ' b'+' b' '\n",
            " b'\\xd1\\x85' b'\\xd0\\xbe' b'\\xd1\\x80' b'\\xd0\\xbe' b'\\xd1\\x88' b'\\xd0\\xb0'\n",
            " b'\\xd1\\x8f' b' ' b'\\xd0\\xbd' b'\\xd0\\xbe' b'\\xd0\\xb2' b'\\xd0\\xbe'\n",
            " b'\\xd1\\x81'], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekyy9ug1ryOK",
        "outputId": "d00667d7-a818-45ef-f1b8-2136bb58279f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Похоже я заболел коронавирусом... Ч.4\n",
            "9 фактов об антибиотиках и резистентности к ним + хорошая новос\n",
            "ть\n",
            "Как на меня повлиял карантин со всеми вытекающими последствиями\n",
            "После карантина\n",
            "Очередная изоляция\n",
            "\n",
            "В шкуре красавчика. Хотя бы так\n",
            "Перу, опять карантин\n",
            "Рост зараженных коронавирусом в Испании\n",
            "В продо\n",
            "лжение\n",
            "Про Covid и Нижний Новгород\n",
            "Ответ на пост «Гречневые магнаты»\n",
            "Гречневые магнаты\n",
            "Расплескалась \n",
            "синева...\n",
            "Ответ на пост «Жизнь врача !»\n",
            "Опять двадцать пять или мой ковид\n",
            "Коронавирус: моя история\n",
            "Чт\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw-eYWupsEXN"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYWxo-81sXI8",
        "outputId": "10736e78-410f-4afc-b751-6e316fc2df49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['t', 'e', 's'], ['e', 's', 't'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "split_input_target(list(\"test\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLGlK5cusYSM"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1nCqzT4sfws",
        "outputId": "929e43c6-6caf-4415-fc14-659d6a3b110f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : Похоже я заболел коронавирусом... Ч.4\n",
            "9 фактов об антибиотиках и резистентности к ним + хорошая ново\n",
            "Target: охоже я заболел коронавирусом... Ч.4\n",
            "9 фактов об антибиотиках и резистентности к ним + хорошая новос\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy().decode('utf-8'))\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4fM7YuysrlD",
        "outputId": "106a27d3-ce11-416f-c72a-e2cea2266d1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LZ6Vz_stSqU"
      },
      "source": [
        "build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPMGSo0ktUtM"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdQFpQPRtgPN"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QQNE5r7t1PT"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Kk2z9cuLJ0"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "z2eJIAUiuKpk",
        "outputId": "dc4f173e-f297-47a7-a6c8-fc42986b9222"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-d5691f3250ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_example_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_example_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mexample_batch_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_example_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_batch_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"# (batch_size, sequence_length, vocab_size)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-513449fc28fc>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, return_state, training)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"my_model_3\" (type MyModel).\n\ntoo many values to unpack (expected 2)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(64, 100), dtype=int64)\n  • states=None\n  • return_state=False\n  • training=False"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVuAtwCCuPY8",
        "outputId": "90ad45a3-ad42-46d4-e820-80ef36c3658c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     multiple                  45056     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               multiple                  5246976   \n",
            "                                                                 \n",
            " dense_3 (Dense)             multiple                  0 (unused)\n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,292,032\n",
            "Trainable params: 5,292,032\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILyHPViTuWZE",
        "outputId": "200a71d8-6f43-4776-b198-1005560a70ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 48,  48, 174,  61,  34,  43, 131,  77, 104,  49,  87, 155, 135,\n",
              "       174,  87, 149,  32,  35,  87, 168,   7,  40,  50, 148,  63,   7,\n",
              "        28, 145,  47,   7,  56, 141,  75,  15,  34,  79,  74, 125, 113,\n",
              "        74, 116,   3,  52,  53, 120, 134,  60,  58,   4, 110, 155,  99,\n",
              "       146, 128,  82,  15,  36, 114,  78, 133, 137,  57, 133, 104, 129,\n",
              "       111, 105, 154,  90,  91, 118,  36, 144,  98, 152,   4,  84, 144,\n",
              "        10, 118,  18,  69,  68,  27, 112, 104,  52,  52, 143, 117, 109,\n",
              "        27, 116,  67,  19,  78,  52,  63, 160, 175])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "\n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w32E98H8unBs",
        "outputId": "8828fd26-8cc7-4cd5-c8eb-e82545a2d929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " фть\n",
            "Ну ее нафиг\n",
            "Минус 15 рублей. Снижать цены на бензин АЗС не могут, потому что потом их будет не п\n",
            "\n",
            "Next Char Predictions:\n",
            " NN€[@IЯlДOvчг€vс>Av—%FPр]%:нM%Vйj-@niЩНiР!RSФвZX\"КчЁоЬq-BОmбеWбДЭЛЕцyzТBм»ф\"sм(Т0dc9МДRRлСЙ9Рb1mR]ь№\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy().decode('utf-8'))\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "186KuYpwvDnc"
      },
      "source": [
        "training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0VZhcPVvE0r"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhtqlEZjvFOD",
        "outputId": "ef1ffdb7-e3f5-452f-f0e8-2bbcd3ff7392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 176)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(5.171282, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzwXNkqQvTXE",
        "outputId": "a9be32ca-595a-48bc-b286-fce1a158f2e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "176.14047"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgslbrZUvW0c"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(), loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kbz2jjdzvaJU"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZECUp22lvh0E"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XacdIHluvda0",
        "outputId": "a7fa6632-fbcc-4ced-c98e-7acbcdc94fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct  7 01:04:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0    30W /  70W |   1200MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "id": "fDAVOlK4vqu8",
        "outputId": "4f82595b-d423-45a6-f0aa-a3b6fe4a2082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-923620710097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"my_model_3\" (type MyModel).\n    \n    in user code:\n    \n        File \"<ipython-input-62-513449fc28fc>\", line 15, in call  *\n            x, states = self.lstm(x, initial_state=states, training=training)\n    \n        ValueError: too many values to unpack (expected 2)\n    \n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(64, 100), dtype=int64)\n      • states=None\n      • return_state=False\n      • training=True\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa1PVrUKwxvr"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3D0lHh_w2PU"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwe9dBc_w_7X",
        "outputId": "ec75b89e-ccea-4972-95d2-6f2cadbb35c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Зачем бро я куклю автомобильный нокирий\n",
            "Скандал в Волгограде моего произведениентся\n",
            "БОДИБ ШЛ? Красная паника\n",
            "5 ощезный луч\n",
            "Игрушки в Доло. МаНК Я РЫНИСАЛЕ САСТИ ССКРАЛ ГАК и ЛОКОЕЛЕ\n",
            "Искатери стоил завяд на Лений\n",
            "Новость №1065: Ученые после заполева в Красноярске. Валявищайся полезны\n",
            "У кого есть машин\n",
            "Миллиард привел в лесу \"панитиры\"\n",
            "Немножко протов про отеце огребенов\n",
            "Продолжение поста «Сарата от IKРЫ? Налово от уходящего лета авто\n",
            "Валатушки\n",
            "Снимали скоточек забыле не области Barcoled и Adplock редолов, на злобу другу отставляют \"Случаи из практики XI. Пост» зленито игновивания из Яндексарт»\n",
            "Выживай собак съемная\n",
            "Простоленно\n",
            "Антипрививочники на Nintendo Switch\n",
            "Принцессы в сентябре 50 вектор\n",
            "Когда ребёнка диракса Maxsung: роман Бегагон\n",
            "Проверканскрым астронателем по райревом всем россиян\n",
            "Власти научилась на первию Ежислона\n",
            "Синдром вахтёра об этом. Унесло и экономика — ли, за это пилот 9. (борзал\n",
            "Женники из Кожда\n",
            "Воспитание\n",
            "Пасхалка на русквой !ифтеры !\n",
            "Весна. Котецы, пожалуйста, что обычно попросить масок\n",
            "Записки кино появившиеся в сентябре\n",
            "Дегораж Да Эмм,ре медуля, сказали при СССР посвящается\n",
            "Броши из бедутского носочек)\n",
            "Сотрудники гречи\n",
            "Тействительность DF: очень онлайн клюбу (она хоже на работу\n",
            "Крольчащи\n",
            "Strarisan\n",
            "Вот и задержание (18 Маля))\n",
            "Приставка для защиты Роп-та как снимаются в сериалах Аптомскей голосов\n",
            "Российские знакомство предложили в Россию мое женщины к психуательной сирут из Чехии\n",
            "Человек сы Гнеза\n",
            "МОСТР\n",
            "Лукашенко\n",
            "Мотиватор России\n",
            "В Пятерочке\n",
            "Абородник, завоте одной многознал\n",
            "Ницер\n",
            "Век Бегус\n",
            "Хуманизация адвоката\n",
            "Басса, распространения коронавируса\n",
            "РПЦ запретила S2.04420\n",
            "Новинки кино появившиеся в сети\n",
            "Коронавирус\n",
            "Будьте здание в Hamf Life\n",
            "Oclsanonn\n",
            "Арты от Cubly a Mica collectioc\n",
            "Мультя-Круз сного фейковы по тоночестве [Фейк]\n",
            "Как коронавирус нельзя лучшим зарплате с туничными заболе 80-хорошь?\n",
            "Мой кота - убойная сокладаются без мечей\n",
            "Осторожно! Порок неожиданного носом.\n",
            "Женская помощь\n",
            "Помогите кроника!\n",
            "Как я напал вид и забал весх пирный и соц.оке вы пролетели и уволит\n",
            "Вопрос к лиге юристов.\n",
            "Будвт, их музыка. Бесплатно\n",
            "Протоивался кредит фантастический стал дерег на работе, предостивет \"Девушка Миссион \"Двадац окорчение. Задерная торька\n",
            "Любимая раздача временно бесплатных игр и приложений лещадь\n",
            "Фантязия или видный армий.\n",
            "Холодная вопрос\n",
            "Гелое кульер\n",
            "\n",
            "Молсткай озер)\n",
            "Назад в детство .49\n",
            "Предвлежаю с това с самым большах\n",
            "Тебушка, дачь все- мне,!) бесполезных расстряка\n",
            "Героя Краут для Валомах\n",
            "Собаки индексию версиюд\n",
            "Что изнутри. Рыбалка.\n",
            "Брусного миллиампера...\n",
            "Сегодня 2019 года Финал\n",
            "Держит своя 4сть, часть 2\n",
            "Стречка фотощадо\n",
            "Как в “Первым эпидемиях Триллера WIPa\n",
            "Уникальная сумьхет, что он , час на один девушку, так не растряка\n",
            "Puluckem: Мaшки-Амурски. Все останьство, и сделали ее\n",
            "Не моё делается Ave истерия с коронавирусом от афинского*ах происходит? 4 июля!\n",
            "Строительство внеминовато время на жители: РКу Пять\n",
            "Большой дворец в Санкт-Петербурге\n",
            "И внеснил костене для знаменитых честно((х. скилли малкинского море\n",
            "Поэтра в Лева\n",
            "Перевоздили майские красивии, ротинули!\n",
            "Что я этого из котом\n",
            "#1 76: битель\n",
            "Обладовань ребенка\n",
            "Начало\n",
            "Лётний модель\n",
            "Воскомная кадры\n",
            "Спарёт на пост «Морской Котик» и получает первый день на beru.ru\n",
            "ЗАЗЕВЛЕнск Крикола\n",
            "Реальный смолы\n",
            "Ну тебе дряжую себе домашний каждо!! - аэропорт (ИСпанки Gonas\n",
            "15 секретов Совсему опять голосование по сароверон\n",
            "Премни, который стоит бесплотие 8 года\n",
            "Как я безопасности России БогорД В Добрали, Карантин\n",
            "Золотое Сальма\n",
            "Закрытие фотографий о фанахе I SLM IVIP(по самаламокуряютской многохороние.\n",
            "Уоказ спустя\n",
            "Холоды среднего орена на МКС\n",
            "Последний выход из картона\n",
            "Гомека — биологическая тропа атактофила\n",
            "Поздно эффективность или как зверьма со следованой ДД»\n",
            "Такой женщин в лес\n",
            "Зпорошь звонит, это прочто такая чка как так по зайбехами\n",
            "Не мог спасти X ApiC\n",
            "2B и + двейнер-клонов: осень об этом?\n",
            "Как я открюбовал внимание в каршеринг: лигрейдеры планировались\n",
            "Ответ на пост «Ответ на пост \"БаЗупские прозителину для треньга\"\n",
            "Март. Паради, который проможды.\n",
            "Спамканский цветах 2020 - балкон\n",
            "Мигренье: почему обучить стройтесь запретили повышение Сафорато\n",
            "Метро Пятнисти...\n",
            "Нето точка\n",
            "Ответ на пост «ОНДЕНДС ПРВ ПОЗОЩИЦА ДАКОНЛЫ НАЯМЫЙ!!\n",
            "Ответ на пост «Работа Сергей-Домбашипол!», \"Всем интернет-мотоциклист)\n",
            "Как и запенить хочется: США запустил нормально выйдет в оказался есть много??\n",
            "Военные волонтеры\n",
            "Стих и ...\n",
            "Росзвервые машины. Азиаты на самоизоляции\n",
            "Сборная война сыгралась\n",
            "Помогите, как есть...\n",
            "Портановитесь !!!!!\n",
            "Москвичу выдвиру\n",
            "Про ракуты\n",
            "Новость гора\n",
            "Учебы в аптеке\n",
            "Дошли учки за мамкин снаги.\n",
            "Проблемы и вот и достаточно\n",
            "Темная тумана\n",
            "Цветы, началось...\n",
            "2020 года. Выгулевная Берра\n",
            "Ответ на пост «Почему я не убили убили знаем развод 9-ДТО, конесловые инструкции G - бананк\n",
            "Роспись масшополись\n",
            "Встретить нашек для подных паден?\n",
            "Момент\n",
            "Мужех налоговой вязы\n",
            "Хаистайские тендии делал\n",
            "Не может борталы? Ни, нукой Бельмовский\n",
            "Этого ходбелька. И не понимаю\n",
            "Кусуль, или минасом в школе с Алиса за один день\n",
            "Даже усорышь, как на моне и с тыря...\n",
            "Застрякам!\n",
            "Когда самый достодней.\n",
            "Индейские катастрофы от Meeente (слебые мы \"закупают \"появились\" с пкольком улитрус.\n",
            "O на молодец). Пригер t «0hми легких и гримп\n",
            "Этот хотешок, бёскоп\n",
            "Хвеста, я другие промокоды\n",
            "Как Сложным уголонная форма домаша игровых ч.1\n",
            "Офиэн в возрусской\n",
            "Резулятная во самых известным плакатиомных украшений\n",
            "Измена блокальцы ...\n",
            "У вас такое всё-таки не так?\n",
            "Откормоневание от цифровоза\n",
            "Грутая купила в детскую празднует Информации от Seyriea\n",
            "Ровет «159й, раздр против волферош»\n",
            "Апска\n",
            "Владельцы Testall работать\n",
            "Морский запасный отправляю всех, кто родился 20 августа!\n",
            "Поздравляю всех, кто родился 32 мая 2019 года\n",
            "Что выбираюм...\n",
            "Суговращение варевника, чтобы на карантине работать на Порт Кайко с таким же принять за черею змузь\n",
            "Карантин (часть 2)\n",
            "Пространство Намереного от белко\n",
            "Польза приговор\n",
            "Реалистичная мросла\n",
            "Королевский район Dayl PriKf Sukveathort\n",
            "Родительный паровоз - значит авто на дороге\n",
            "Вирус Хроночество\n",
            "Эффективный мужей подходил фотографии с трегкольными зуманием...\n",
            "Хэта убитал\n",
            "А Уд усел дли новым коди...\n",
            "Фильмы месяца. Марти ?\n",
            "СПУска готовится к сезон и разгодарство в переодеть во время мозга не паники\n",
            "Наскролос?\n",
            "Чекопесанло...\n",
            "Слава театера\n",
            "В Татеринском условиях\n",
            "Shorls Mart 2\n",
            "Пандемия жизни\n",
            "Вместе. продавал эпидемию\n",
            "Лучший работник из бумаги (ина - крутой путь\n",
            "Пипа, кок собседиет на моне виновато...\n",
            "Забота и пандиких\n",
            "Во блокифорке-Беглов приопаганды vs разнодерные животные\n",
            "Blackake\n",
            "Коротко о железеченные коронавирусом\n",
            "Курортные вамное\n",
            "Реклама невеста)\n",
            "Когда ты правда жизни?\n",
            "Вакцинация кота разумался выплат такие родителем.\n",
            "Кукла ручной работы\n",
            "Шутка фрейдро и грузовиков\n",
            "Якутизм\n",
            "Мы ийно,фанские прязнаки на 300 лет 15 тыл прочитавие сут и против воля\n",
            "Перебодное решение Бондовы БАр БЭлло\n",
            "Нежназивок Ростелеку\n",
            "Детская сельфов\n",
            "Нарисовализ\n",
            "Анимер AsBa\n",
            "Mike ugn cale. Моя одна помощь фильма\n",
            "Скоростнующей под здестали в убийстве Фволога. расисты короловь Fol Bay Manime :)\n",
            "Когда простой вино. Часть 3\n",
            "Фэнтези по-русски, или очередной узок\n",
            "Изучем апоксовромено бора\n",
            "Амянор на горника\n",
            "В Кабырсе БАПСИ ЗАвирно-килоонов\n",
            "Восвледетев с карманом\n",
            "Практикантного 4.18.202 не хватает актрофоническим\n",
            "Не было и вот опять!\n",
            "До начал.\n",
            "Срочно нулет\n",
            "Про западник обрушения из разбибается на 2,5 молодо. Глава 46\n",
            "Неизуровень Sluckall для деду\n",
            "Как у \"мерткам стали \"Грусти к нем нужен свадьба защита от \"полным\" или ищит адпуса\n",
            "Сила притчу, и я как их делал :еона с ним + мифа!\n",
            "Почему я удаля собаку в Москве наступило\n",
            "Полышадься, мамон со спалом Васков\"\n",
            "Ловят вашей нас!\n",
            "Про детской жизни\n",
            "Crisa Bess Adssen\n",
            "Andats. Кротивое сердце\n",
            "Новая жизнь\n",
            "Мику\n",
            "Пофопы возмущилась, империали после обмана россиягового судья вариант 90хлаченная боля\n",
            "Сказ Филля на вино ю рисуе. Не понимаю свидепол!\n",
            "Магиз на уже что?\n",
            "Технику\n",
            "Тестируем бесшим тура,ме — ожим, паникующий говорят ромкае в Беларуси\n",
            "Этот боли : древник — это повозмойвный и музей газовой получил\n",
            "Никогда такого хотят пути, как заболевшим с высоты :)\n",
            "Senaxoi порак в Ваньке\n",
            "Какую-низ духал, Солнечная система во время баброслетний.\n",
            "Дело и Фоторейского\n",
            "Вспомнить объявлен коронавирус в Италии против заработок Cosa высотики R200%\n",
            "Боки с коронавирусом вызвали переводов - 84\n",
            "Небольшая подборка переводов - 92\n",
            "Небольшая подборка переводов - 1лли\n",
            "Вечер Хозяйва 1\n",
            "Дом предпринимателе\n",
            "Тресс\n",
            "Мнигах стран\n",
            "Lintetg\n",
            "Marsa\n",
            "Bun\n",
            "Kame is lead\n",
            "На самоизоляции\n",
            "Казаня по информатике I MB Have-noden\n",
            "Aplat Arvito\n",
            "SE Chacker Speads 1\n",
            "80:0 Лета. Как сделать из домашним родственников\n",
            "На волне про прокатилось истерить в Синга-июнь\n",
            "Оживание к другим статистиках на коронавирус спрежена новую книгу (с силамами деревяна в ваших странах\n",
            "Конспирологич. Маленькие недели добрываются!\n",
            "Быбология - подарил, до погибла? Лосьа\n",
            "Гопуст на стадии разработки квест «Похудели \"сухона\"\n",
            "Во выдумки на работе\n",
            "Продолжение\n",
            "Голога в реальных ученых, видим, если быть?\n",
            "Вся старьение\n",
            "Новость, мои тарыг\n",
            "Где на Минах! ОНИ по-русски\n",
            "Коронавирус Бsauouamataau-заправили до деревьев\n",
            "Картина \"Пирыми, ножали» в Санаточно\n",
            "Как души в клубе, почему мы я ответ !\n",
            "Моино до подешев за небеса чемпионарины некрогиваются!\n",
            "Будни магазина! Что обрать вино?\n",
            "Карантинное платение о паваемого сезона «Тана или на ведьмаке, Если бы) дом Про обычной \"залотые деревья\" дипломатов\n",
            "Служба зласит собаки\n",
            "Star ia Spiver\n",
            "Сочи\n",
            "Путешествовать с ломатьха клинов спитализация\n",
            "Невероятные приключения!\n",
            "В тему шаговая больницы и не дают\n",
            "Волшебная находящая катастрофа оказался неадекватала. Я начал писать сюществовать\n",
            "Bleaw или как из Люнь. Танкел\n",
            "Кондусь родают гречты lete ты тут не повезло\n",
            "Пятый Питер, поохотить на приранени х. Ажнак, заявили о Испании в истории пчела! Фотопроми ожм и слышал можно и сыром\n",
            "Как я проблемы людей\n",
            "Buethuru Cod Faiser\n",
            "Перешаю профко даже вещей.\n",
            "Куда почему и гулять! 3 людий!\n",
            "Горы аженимый хуможницы DOM Ener farte\n",
            "Mossing\n",
            "Ая?\n",
            "Просто не намая\n",
            "Пушистый путь в Дью Опять\n",
            "Социальная читья!\n",
            "Всём родителей. Как над Джорджа по Москве (светчик\n",
            "Маска свадьба все бывает решения\n",
            "Прости господи...\n",
            "А вы в городе Гэй!\n",
            "Когда хозяин решил поймал машем об аниме \"Бережной море!). Аннара, Якутся?»\n",
            "Так и ос \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 26.38192105293274\n"
          ]
        }
      ],
      "source": [
        "textlen = 10000\n",
        "\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Зачем бро '])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(textlen):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DX1iC6B__MFT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WRXdoWbN0nB0"
      },
      "outputs": [],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VXGd_ytA1DuV"
      },
      "outputs": [],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['a:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4edeOmX11GsW"
      },
      "source": [
        "another one трай"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TO1gbXGO1ONd"
      },
      "outputs": [],
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(inputs, training=True)\n",
        "          loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpzDE1ZZ1_9c"
      },
      "outputs": [],
      "source": [
        "model1 = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtOnpGw02e7M"
      },
      "outputs": [],
      "source": [
        "model1.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "yKGddAsU3dXl",
        "outputId": "a7996068-0895-482b-9346-47805b8cc5a5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-605bea89c862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model1' is not defined"
          ]
        }
      ],
      "source": [
        "model1.fit(dataset, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "RdsYWQ8s2hjU",
        "outputId": "cb33a1f6-3a4a-41b7-ed6c-e4f3d7e7dda5"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-bc00d10abc6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"<ipython-input-51-f4fa1f7b1d4c>\", line 9, in train_step  *\n        self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 633, in apply_gradients  **\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/utils.py\", line 73, in filter_empty_gradients\n        raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\n    ValueError: No gradients provided for any variable: (['my_model/embedding/embeddings:0', 'my_model/gru/gru_cell/kernel:0', 'my_model/gru/gru_cell/recurrent_kernel:0', 'my_model/gru/gru_cell/bias:0', 'my_model/dense/kernel:0', 'my_model/dense/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'my_model/embedding/embeddings:0' shape=(165, 256) dtype=float32>), (None, <tf.Variable 'my_model/gru/gru_cell/kernel:0' shape=(256, 3072) dtype=float32>), (None, <tf.Variable 'my_model/gru/gru_cell/recurrent_kernel:0' shape=(1024, 3072) dtype=float32>), (None, <tf.Variable 'my_model/gru/gru_cell/bias:0' shape=(2, 3072) dtype=float32>), (None, <tf.Variable 'my_model/dense/kernel:0' shape=(1024, 165) dtype=float32>), (None, <tf.Variable 'my_model/dense/bias:0' shape=(165,) dtype=float32>)).\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model1.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "    # saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model1.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model1.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBqFq2LCoR4bm3Mevr4UOX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}